# -*- coding: utf-8 -*-
"""Structured_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Lw7bJTpP4DPZ9e1tAM2NtUhuZVFl_QF
"""

# -*- coding: utf-8 -*-
#Social Media Usage & Addiction â€” Structured EDA Pipeline

#Setup & Imports
import sys
import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

sns.set_theme(context="notebook", style="whitegrid")

#uncomment the upload section below if in Google collab
IN_COLAB = "google.colab" in sys.modules

CSV_FILENAME = "Students_Social_Media_Addiction.csv"  #default expected name

#Config
#Column alias map to standardize various possible headings
COLUMN_ALIASES = {
    #Usage
    "Average_Daily_Usage_Hours": "Average_Daily_Usage_Hours",
    "Avg_Daily_Usage_Hours": "Average_Daily_Usage_Hours",
    "Avg_Daily_Usage": "Average_Daily_Usage_Hours",

    #Addiction score
    "Addiction_Score": "Addiction_Score",
    "Addicted_Score": "Addiction_Score",

    #Sleep
    "Sleep_Hours_Per_Night": "Sleep_Hours",
    "Sleep_Hours": "Sleep_Hours",

    #Mental Health
    "Mental_Health_Score": "Mental_Health_Score",

    #Academic impact
    "Impact_on_Academic_Performance": "Impact_on_Academic_Performance",
    "Affects_Academic_Performance": "Impact_on_Academic_Performance",

    #Categoricals
    "Most_Used_Platform": "Most_Used_Platform",
    "Gender": "Gender",
    "Academic_Level": "Academic_Level",
    "Country": "Country",
    "Relationship_Status": "Relationship_Status",
    "Conflicts_Over_Social_Media": "Conflicts_over_Social_Media",
    "Conflicts over Social Media": "Conflicts_over_Social_Media",

    #Demographics
    "Age": "Age",
}

CATEGORICAL_COLUMNS = [
    "Gender", "Academic_Level", "Most_Used_Platform", "Country",
    "Relationship_Status", "Conflicts_over_Social_Media"
]

NUMERIC_COLUMNS_CORE = [
    "Average_Daily_Usage_Hours", "Addiction_Score", "Sleep_Hours",
    "Mental_Health_Score", "Age"
]

#Utilities
def print_section(title):
    print("\n" + "="*len(title))
    print(title)
    print("="*len(title))

def standardize_columns(df, aliases):
    """Rename columns to a clean canonical set using aliases."""
    new_cols = {}
    for col in df.columns:
        new_cols[col] = aliases.get(col, col)
    return df.rename(columns=new_cols)

def coerce_numeric(df, cols):
    """Coerce a list of columns to numeric if present."""
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

def normalize_binary_yes_no(series):
    """Map variants to Yes/No categories (returns category dtype)."""
    s = series.astype(str).str.strip().str.lower()
    yes_vals = {"yes", "y", "true", "1", "conflict", "sometimes", "occasionally"}
    no_vals  = {"no", "n", "false", "0", "none", "never"}

    mapping = {val: "Yes" for val in yes_vals}
    mapping.update({val: "No" for val in no_vals})

    #Map and convert to category dtype
    return s.map(mapping).astype("category")


def show_value_counts(df, col, normalize=False):
    if col in df.columns:
        return df[col].value_counts(normalize=normalize, dropna=False).sort_values(ascending=False)
    return pd.Series(dtype="int64")

def bar_plot_counts(df, col, title, figsize=(9,5)):
    if col not in df.columns:
        print(f"[WARN] Column '{col}' missing. Skipping plot.")
        return
    counts = df[col].value_counts(dropna=False)
    plt.figure(figsize=figsize)
    sns.barplot(x=counts.index.astype(str), y=counts.values)
    plt.title(title)
    plt.ylabel("Count")
    plt.xlabel(col)
    plt.xticks(rotation=30, ha="right")
    plt.tight_layout()
    plt.show()

def box_plot(df, x, y, title, figsize=(9,5)):
    if x not in df.columns or y not in df.columns:
        print(f"[WARN] Missing columns for boxplot: {x}, {y}. Skipping.")
        return
    plt.figure(figsize=figsize)
    sns.boxplot(data=df, x=x, y=y)
    plt.title(title)
    plt.xticks(rotation=30, ha="right")
    plt.tight_layout()
    plt.show()

def dist_plot(df, col, title, bins=30, figsize=(9,5)):
    if col not in df.columns:
        print(f"[WARN] Column '{col}' missing. Skipping distplot.")
        return
    plt.figure(figsize=figsize)
    sns.histplot(df[col].dropna(), bins=bins, kde=True)
    plt.title(title)
    plt.xlabel(col)
    plt.tight_layout()
    plt.show()

def scatter_plot(df, x, y, title, hue=None, figsize=(8,6)):
    for c in [x, y]:
        if c not in df.columns:
            print(f"[WARN] Missing column '{c}' for scatter. Skipping.")
            return
    plt.figure(figsize=figsize)
    sns.scatterplot(data=df, x=x, y=y, hue=(hue if hue in df.columns else None))
    plt.title(title)
    plt.tight_layout()
    plt.show()

def heatmap_corr(df, cols, title, figsize=(7,5)):
    cols_present = [c for c in cols if c in df.columns]
    if len(cols_present) < 2:
        print("[WARN] Not enough numeric columns for correlation heatmap.")
        return
    corr = df[cols_present].corr()
    plt.figure(figsize=figsize)
    sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
    plt.title(title)
    plt.tight_layout()
    plt.show()
    return corr

#Data Loading
if IN_COLAB:
    try:
        from google.colab import files
        print_section("Upload CSV")
        print("Please upload your dataset (CSV).")
        uploaded = files.upload()  # user picks file in Colab
        if len(uploaded) == 1:
            CSV_FILENAME = list(uploaded.keys())[0]
            print(f"Using uploaded file: {CSV_FILENAME}")
    except Exception as e:
        print(f"[INFO] Not in Colab upload mode or upload failed: {e}")

print_section("Load Dataset")
df_raw = pd.read_csv(CSV_FILENAME)
print(f"Rows: {len(df_raw)}, Columns: {len(df_raw.columns)}")

#Standardize Columns, Types, and Missing Values
print_section("Standardize Columns & Types")
df = standardize_columns(df_raw.copy(), COLUMN_ALIASES)

#Making sure Conflicts column is normalized to Yes/No
if "Conflicts_over_Social_Media" in df.columns:
    df["Conflicts_over_Social_Media"] = normalize_binary_yes_no(df["Conflicts_over_Social_Media"])

#Coerce numeric columns
df = coerce_numeric(df, NUMERIC_COLUMNS_CORE)

#Trim strings in categoricals
for c in CATEGORICAL_COLUMNS:
    if c in df.columns and df[c].dtype == object:
        df[c] = df[c].astype(str).str.strip()

#Show head and dtypes
display(df.head())
display(df.dtypes)

#Missing values summary
print_section("Missing Values")
display(df.isna().sum())

#Simple missing handling strategy:
df_clean = df.copy()

#Save a cleaned copy with standardized names & basic type coercion
df_clean.to_csv("students_social_media_cleaned.csv", index=False)
print("Saved: students_social_media_cleaned.csv")

#Beginner Questions
print_section("Beginner: Data Loading & Initial Exploration")
#First 5 rows already shown; show categorical uniques:
for col in CATEGORICAL_COLUMNS:
    if col in df_clean.columns:
        uniq = df_clean[col].nunique(dropna=True)
        print(f"{col}: {uniq} unique values")
        display(show_value_counts(df_clean, col))

print_section("Beginner: Descriptive Statistics (Numerical)")
numeric_cols_present = [c for c in NUMERIC_COLUMNS_CORE if c in df_clean.columns]
display(df_clean[numeric_cols_present].describe())

#Usage Patterns
print_section("Beginner: Usage Patterns")
if "Average_Daily_Usage_Hours" in df_clean.columns:
    avg_usage = df_clean["Average_Daily_Usage_Hours"].mean()
    print(f"Average of Average_Daily_Usage_Hours: {avg_usage:.2f} hours")

#Most popular platform + visualization
if "Most_Used_Platform" in df_clean.columns:
    bar_plot_counts(df_clean, "Most_Used_Platform", "Most Popular Social Media Platform")

#Usage by Gender and Academic Level
box_plot(df_clean, "Gender", "Average_Daily_Usage_Hours", "Daily Usage by Gender")
box_plot(df_clean, "Academic_Level", "Average_Daily_Usage_Hours", "Daily Usage by Academic Level")

#Basic Impact Assessment
print_section("Beginner: Basic Impact Assessment")
if "Impact_on_Academic_Performance" in df_clean.columns:
    bar_plot_counts(df_clean, "Impact_on_Academic_Performance", "Impact on Academic Performance (Distribution)")

    #Average Sleep_Hours by impact (Positive/Negative/Neutral)
    if "Sleep_Hours" in df_clean.columns:
        sleep_by_impact = df_clean.groupby("Impact_on_Academic_Performance", dropna=False)["Sleep_Hours"].mean().sort_values(ascending=False)
        print("Average Sleep_Hours by Impact_on_Academic_Performance:")
        display(sleep_by_impact)

#Addiction Score Basics
print_section("Beginner: Addiction Score Basics")
if "Addiction_Score" in df_clean.columns:
    avg_addiction = df_clean["Addiction_Score"].mean()
    print(f"Average Addiction_Score: {avg_addiction:.2f}")

if set(["Addiction_Score", "Average_Daily_Usage_Hours"]).issubset(df_clean.columns):
    corr_adduse = df_clean[["Addiction_Score", "Average_Daily_Usage_Hours"]].corr().iloc[0,1]
    print(f"Correlation (Addiction_Score vs Average_Daily_Usage_Hours): {corr_adduse:.3f}")
    scatter_plot(df_clean, "Average_Daily_Usage_Hours", "Addiction_Score",
                 "Addiction Score vs Daily Usage (Scatter)")

#Relationship Conflicts Overview
print_section("Beginner: Relationship Conflicts Overview")
if "Conflicts_over_Social_Media" in df_clean.columns:
    conflict_pct = (df_clean["Conflicts_over_Social_Media"] == "Yes").mean() * 100
    print(f"Percentage reporting Conflicts_over_Social_Media: {conflict_pct:.2f}%")

    cols_to_compare = [c for c in ["Average_Daily_Usage_Hours", "Addiction_Score"] if c in df_clean.columns]
    if cols_to_compare:
        comparison = df_clean.groupby("Conflicts_over_Social_Media")[cols_to_compare].mean()
        print("Mean comparison by conflicts (Yes/No):")
        display(comparison)

#Intermediate Questions
#In-depth Addiction and Well-being Analysis
print_section("Intermediate: Addiction & Well-being Correlations")
corr_cols = [c for c in ["Addiction_Score", "Mental_Health_Score", "Sleep_Hours"] if c in df_clean.columns]
corr_mat = heatmap_corr(df_clean, corr_cols, "Correlation: Addiction, Mental Health, Sleep")

#Addiction score by platform
print_section("Intermediate: Addiction Score by Platform")
if set(["Most_Used_Platform", "Addiction_Score"]).issubset(df_clean.columns):
    platform_add = df_clean.groupby("Most_Used_Platform")["Addiction_Score"].mean().sort_values(ascending=False)
    display(platform_add)
    plt.figure(figsize=(10,5))
    sns.barplot(x=platform_add.index, y=platform_add.values)
    plt.title("Average Addiction Score by Most Used Platform")
    plt.ylabel("Average Addiction Score")
    plt.xticks(rotation=30, ha="right")
    plt.tight_layout()
    plt.show()

#Social Media Impact on Relationships
print_section("Intermediate: Conflicts vs Usage/Addiction")
if "Conflicts_over_Social_Media" in df_clean.columns:
    cols = [c for c in ["Average_Daily_Usage_Hours", "Addiction_Score"] if c in df_clean.columns]
    if cols:
        grouped = df_clean.groupby("Conflicts_over_Social_Media")[cols].agg(["mean","median","count"])
        display(grouped)

        #Quantify relationship: point-biserial correlations (Yes/No vs numeric)
        #Encode Yes=1, No=0 for correlation check
        enc = (df_clean["Conflicts_over_Social_Media"] == "Yes").astype(float)
        for c in cols:
            valid = df_clean[c].notna() & enc.notna()
            if valid.sum() > 2:
                corr_val = np.corrcoef(df_clean.loc[valid, c], enc[valid])[0,1]
                print(f"Point-biserial-like correlation ({c} vs Conflicts Yes/No): {corr_val:.3f}")

#Relationship Status influences
print_section("Intermediate: Relationship Status vs Usage/Addiction")
if "Relationship_Status" in df_clean.columns:
    cols = [c for c in ["Average_Daily_Usage_Hours", "Addiction_Score"] if c in df_clean.columns]
    if cols:
        rs_comp = df_clean.groupby("Relationship_Status")[cols].mean().sort_values(by=cols[0], ascending=False)
        display(rs_comp)

#Segmenting Student Behaviors (K-Means)
print_section("Intermediate: Clustering / Segments (K-Means)")
cluster_features = [c for c in ["Average_Daily_Usage_Hours", "Addiction_Score", "Sleep_Hours", "Mental_Health_Score"] if c in df_clean.columns]
df_cluster = df_clean[cluster_features].dropna()

if len(cluster_features) >= 2 and len(df_cluster) >= 10:
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(df_cluster.values)

    #Quick elbow & silhouette hint (k=2..6)
    ks = list(range(2, 7))
    inertias, sils = [], []
    for k in ks:
        kmeans_tmp = KMeans(n_clusters=k, random_state=42, n_init=10)
        labels_tmp = kmeans_tmp.fit_predict(X_scaled)
        inertias.append(kmeans_tmp.inertia_)
        sils.append(silhouette_score(X_scaled, labels_tmp))

    #Choose k with max silhouette
    best_k = ks[int(np.argmax(sils))]
    print(f"Elbow inertias: {dict(zip(ks, np.round(inertias,1)))}")
    print(f"Silhouette scores: {dict(zip(ks, np.round(sils,3)))}")
    print(f"Chosen k (max silhouette): {best_k}")

    kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(X_scaled)

    #Attach to a copy of df_clean aligned by index after dropna
    df_segments = df_clean.copy()
    df_segments.loc[df_cluster.index, "Cluster"] = cluster_labels

    #Visualize clusters in Addiction_Score vs Average_Daily_Usage_Hours
    if set(["Addiction_Score", "Average_Daily_Usage_Hours"]).issubset(df_segments.columns):
        plt.figure(figsize=(8,6))
        sns.scatterplot(data=df_segments.dropna(subset=["Cluster"]),
                        x="Addiction_Score", y="Average_Daily_Usage_Hours",
                        hue="Cluster", palette="Set2")
        plt.title("Student Segments by Usage and Addiction (K-Means)")
        plt.tight_layout()
        plt.show()

    #Segment characteristics
    seg_stats_cols = [c for c in ["Average_Daily_Usage_Hours", "Addiction_Score", "Sleep_Hours", "Mental_Health_Score", "Age"] if c in df_segments.columns]
    seg_profile = df_segments.groupby("Cluster")[seg_stats_cols].agg(["mean", "median", "count"])
    print("Cluster segment characteristics:")
    display(seg_profile)

    df_segments.to_csv("students_social_media_with_clusters.csv", index=False)
    print("Saved: students_social_media_with_clusters.csv")
else:
    print("[INFO] Not enough features or rows for clustering. Skipping.")

#Geographical & Demographic Insights
print_section("Intermediate: Geographical & Demographic Insights")
#Differences across Country
if set(["Country", "Addiction_Score"]).issubset(df_clean.columns):
    country_stats = df_clean.groupby("Country")["Addiction_Score"].mean().sort_values(ascending=False)
    print("Top countries by average Addiction_Score:")
    display(country_stats.head(10))

    plt.figure(figsize=(10,5))
    top10 = country_stats.head(10)
    sns.barplot(x=top10.index, y=top10.values)
    plt.title("Top 10 Countries by Average Addiction_Score")
    plt.xticks(rotation=30, ha="right")
    plt.tight_layout()
    plt.show()

if set(["Country", "Average_Daily_Usage_Hours"]).issubset(df_clean.columns):
    country_usage = df_clean.groupby("Country")["Average_Daily_Usage_Hours"].mean().sort_values(ascending=False)
    print("Top countries by average Average Daily Usage Hours:")
    display(country_usage.head(10))

#Age & Academic Level influence
if "Age" in df_clean.columns:
    #Smooth trend via groupby on Age if wide range
    age_grp = df_clean.dropna(subset=["Age"]).copy()
    age_grp["Age"] = age_grp["Age"].astype(int)
    age_trend_cols = [c for c in ["Addiction_Score", "Average_Daily_Usage_Hours"] if c in age_grp.columns]
    if age_trend_cols:
        age_trend = age_grp.groupby("Age")[age_trend_cols].mean()
        plt.figure(figsize=(9,5))
        for c in age_trend_cols:
            plt.plot(age_trend.index, age_trend[c], marker="o", label=c)
        plt.title("Age vs Usage & Addiction (Averaged by Age)")
        plt.xlabel("Age")
        plt.legend()
        plt.tight_layout()
        plt.show()
        display(age_trend.tail())

if set(["Academic_Level", "Addiction_Score"]).issubset(df_clean.columns):
    box_plot(df_clean, "Academic_Level", "Addiction_Score", "Addiction Score by Academic Level")
if set(["Academic_Level", "Average_Daily_Usage_Hours"]).issubset(df_clean.columns):
    box_plot(df_clean, "Academic_Level", "Average_Daily_Usage_Hours", "Daily Usage by Academic Level")